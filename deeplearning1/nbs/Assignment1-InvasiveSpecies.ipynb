{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1 - Invasive Species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/invasivespecies/'\n",
    "# path = 'data/invasivespecies/sample/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "\n",
    "# Dataset formatting\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/data\n",
      "/home/ubuntu/courses/deeplearning1/nbs\n"
     ]
    }
   ],
   "source": [
    "# Just testing out command line\n",
    "%cd data\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kg config -g -c 'invasive-species-monitoring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unzip training folder\n",
    "originals_folder = path+'train_original/'\n",
    "# !7z --help\n",
    "if not os.path.exists(originals_folder):\n",
    "    !7z e {path}train.7z -o{output_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 4590\n",
      "Positives: 1448 Percent: 0.315468409586\n"
     ]
    }
   ],
   "source": [
    "# Get training labels\n",
    "training_labels_df = pd.read_csv(path + 'train_labels.csv')\n",
    "size = training_labels_df.size\n",
    "num_positives = training_labels_df['invasive'].sum()\n",
    "print('Size:', size)\n",
    "print('Positives: {} Percent: {}'.format(num_positives, num_positives/size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get training files\n",
    "import re\n",
    "\n",
    "_, _, filenames = next(walk(originals_folder))\n",
    "\n",
    "\n",
    "p = re.compile('^([0-9]+).jpg')\n",
    "def find_file_id(filename):\n",
    "    m = p.match(filename)\n",
    "    if m is not None:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        print('Could not regex filename: ', filename)\n",
    "        return -1\n",
    "file_ids = map(find_file_id, filenames)\n",
    "\n",
    "# Merge data into one dataframe:\n",
    "file_df = pd.DataFrame([file_ids, filenames], index=['name', 'file']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label files and move to labeled folder\n",
    "from shutil import copyfile\n",
    "\n",
    "labeled_folder = path+'labeled/'\n",
    "if not os.path.exists(labeled_folder):\n",
    "    os.makedirs(labeled_folder)\n",
    "    \n",
    "labeled_df = pd.merge(training_labels_df, file_df, on='name')\n",
    "for row in labeled_df.itertuples():\n",
    "    label = 'invasive.' if row[2] == 1 else 'noninvasive.'\n",
    "    file_name = row[3]\n",
    "    new_file = labeled_folder+label+file_name;\n",
    "    copyfile(originals_folder+file_name, new_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2295\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "train_folder = path+'train/'\n",
    "shutil.copytree(labeled_folder, train_folder)\n",
    "_, _, filenames = next(walk(train_folder))\n",
    "shuf = np.random.permutation(filenames)\n",
    "size = len(filenames)\n",
    "print(size)\n",
    "\n",
    "valid_folder = path+'valid/'\n",
    "if not os.path.exists(valid_folder):\n",
    "    os.makedirs(valid_folder)\n",
    "    \n",
    "sample_train_folder = path+'sample/train/'\n",
    "if not os.path.exists(sample_train_folder):\n",
    "    os.makedirs(sample_train_folder)\n",
    "for i in range(200):\n",
    "    copyfile(train_folder+shuf[i], sample_train_folder+shuf[i])\n",
    "    \n",
    "sample_valid_folder = path+'sample/valid/'\n",
    "if not os.path.exists(sample_valid_folder):\n",
    "    os.makedirs(sample_valid_folder)\n",
    "for i in range(200):\n",
    "    copyfile(train_folder+shuf[i], sample_valid_folder+shuf[i])\n",
    "    \n",
    "validation_size = int(round(size * .3))\n",
    "for i in range(validation_size):\n",
    "    os.rename(train_folder+shuf[i], valid_folder+shuf[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_folders(folder):\n",
    "    if not os.path.exists(folder+'noninvasive'):\n",
    "        os.makedirs(folder+'noninvasive')\n",
    "        os.makedirs(folder+'invasive')\n",
    "    inv = glob(folder+'invasive.*.jpg')\n",
    "    noninv = glob(folder+'noninvasive.*.jpg')\n",
    "    move_files_to(inv, folder, folder+'invasive/')\n",
    "    move_files_to(noninv, folder, folder+'noninvasive/')\n",
    "    \n",
    "def move_files_to(files, old_folder, new_folder):\n",
    "    for fname in files:\n",
    "        newf = fname.replace(old_folder, new_folder)\n",
    "        os.rename(fname, newf)\n",
    "        \n",
    "classify_folders(sample_train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/invasivespecies/sample/train/invasive/invasive.1903.jpg'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv = glob(sample_train_folder+'invasive.*.jpg')\n",
    "f = inv[0]\n",
    "f\n",
    "newf = f.replace(sample_train_folder, sample_train_folder+'invasive/')\n",
    "newf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size=64\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=4)\n",
    "imgs,labels = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(imgs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.predict(imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.classes[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune Cats and Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_vgg():\n",
    "    batch_size=64\n",
    "    batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "    val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "    vgg.finetune(batches)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "\n",
    "    vgg.model.save_weights(weights_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "weights_file = 'trained_weights.h5'\n",
    "weights_fullpath = path+'models/'+weights_file\n",
    "if os.path.exists(weights_fullpath):\n",
    "    vgg.model.load_weights(weights_fullpath)\n",
    "    print('Loaded model from cache')\n",
    "else:\n",
    "    train_vgg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict results in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folderName = 'test'\n",
    "num_test_images = 12500\n",
    "test_batch_size = 100\n",
    "\n",
    "# folderName = 'sample/test'\n",
    "# num_test_images = 8\n",
    "# test_batch_size = 1\n",
    "\n",
    "batches = vgg.get_batches(path+folderName, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "# with open('train.csv', 'wb') as csvfile:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "filenames = batches.filenames\n",
    "filename = filenames[0]\n",
    "print(filename)\n",
    "\n",
    "p = re.compile('.*/([0-9]+).jpg')\n",
    "m = p.match(filename)\n",
    "m.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our predictions..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing batch results\n",
    "test_batch_size = 10\n",
    "batches = vgg.get_batches(path+folderName, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "imgs = next(batches)\n",
    "labels, a, b = vgg.predict(imgs, True)\n",
    "# This shows the 'ground truth'\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert file names to label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "filenames = batches.filenames\n",
    "\n",
    "p = re.compile('.*/([0-9]+).jpg')\n",
    "def find_file_id(filename):\n",
    "    m = p.match(filename)\n",
    "    if m is not None:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        print('Could not regex filename: ', filename)\n",
    "        return -1\n",
    "file_ids = map(find_file_id, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option A: Predict values using vgg test function (Not recommended. No progress)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing batch results\n",
    "batches, predictions = vgg.test(path+folderName, batch_size=1)\n",
    "# print('A: ', batches)\n",
    "p_results = predictions[:, 1]\n",
    "\n",
    "print('Predictions: ', p_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option B: Predict values with batches and progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "predict_file = path + 'models/predict.npy'\n",
    "\n",
    "def predict_test():\n",
    "    batches = vgg.get_batches(path+folderName, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "\n",
    "    p_results = np.zeros(num_test_images)\n",
    "    current_index = 0\n",
    "    # Iterative loop\n",
    "    for batch in tqdm(batches, total=math.ceil(num_test_images/test_batch_size)):\n",
    "        if batch is None:\n",
    "            break\n",
    "        p = vgg.model.predict_on_batch(batch)\n",
    "        p_dog = p[:, 1]\n",
    "        p_size = p.shape[0]\n",
    "    #     print('Predictions: {}\\n Size: {}'.format(dog_p, p_size))\n",
    "        new_index = current_index + p_size\n",
    "        p_results[current_index:new_index] = p_dog\n",
    "        current_index = new_index\n",
    "        if current_index >= num_test_images:\n",
    "            break\n",
    "    print(p_results)\n",
    "    np.save(predict_file)\n",
    "\n",
    "if os.path.exists(predict_file):\n",
    "    np.load(predict_file)\n",
    "    print('Loaded predictions from cache')\n",
    "else:\n",
    "    predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the arrays match\n",
    "print(p_results.shape)\n",
    "print(len(file_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine ids with labels and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg = pd.DataFrame({'id': file_ids, 'label': p_results})\n",
    "agg = agg.sort_values(['id'])\n",
    "print(agg)\n",
    "agg.to_csv(path + 'predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing VGG with Keras Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILES_PATH = 'http://files.fast.ai/models/'\n",
    "CLASS_FILE='imagenet_class_index.json'\n",
    "fpath = get_file(CLASS_FILE, FILES_PATH+CLASS_FILE, cache_subdir='models')\n",
    "with open(fpath) as f:\n",
    "    class_dict = json.load(f)\n",
    "# classes = [class_dict[i][1] for i in class_dict]\n",
    "classes = [class_dict[str(i)][1] for i in range(len(class_dict))] # original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ??Convolution2D\n",
    "\n",
    "# ??MaxPooling2D\n",
    "\n",
    "# ??Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??MaxPooling2D\n",
    "\n",
    "??Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = get_file('vgg16.h5', FILES_PATH+'vgg16.h5', cache_subdir='models')\n",
    "model.load_weights(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = get_batches('train', batch_size=batch_size)\n",
    "val_batches = get_batches('valid', batch_size=batch_size)\n",
    "imgs,labels = next(batches)\n",
    "\n",
    "# This shows the 'ground truth'\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_batch(imgs):\n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Shape: {}'.format(preds.shape))\n",
    "    print('First 5 classes: {}'.format(classes[:5]))\n",
    "    print('First 5 probabilities: {}\\n'.format(preds[0, :5]))\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print ('  {:.4f}/{}'.format(preds[i, idx], classes[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_batch(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
