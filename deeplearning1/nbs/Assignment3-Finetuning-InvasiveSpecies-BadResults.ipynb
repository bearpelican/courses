{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 - Invasive Species - Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import plots\n",
    "\n",
    "# Dataset formatting\n",
    "from os import walk\n",
    "import shutil\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data/invasivespecies/'\n",
    "\n",
    "# NEVER ENABLE THIS WHEN CREATING VALIDATION SET (STEP 1)\n",
    "# path = 'data/invasivespecies/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = path+'models/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "# batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=4)\n",
    "imgs,labels = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(imgs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.predict(imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.classes[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_data = get_data(path+'valid')\n",
    "trn_data = get_data(path+'train')\n",
    "save_array(model_path+'train_data.bc', trn_data)\n",
    "save_array(model_path+'valid_data.bc', val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'valid_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n",
    "batches = get_batches(path+'train', shuffle=False, batch_size=1)\n",
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the class ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Valuation distribution: ', sum(val_labels))\n",
    "print('Percentages: ', sum(val_labels) / val_labels.shape[0])\n",
    "\n",
    "print('Training distribution: ', sum(trn_labels))\n",
    "print('Percentages: ', sum(trn_labels) / trn_labels.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 0: Use Batch Normalization and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [index for index,layer in enumerate(layers) if type(layer) is Convolution2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_layers[-1].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(last_conv_idx)\n",
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1000, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fc_weights_from_vgg16bn(model):\n",
    "    from vgg16bn import Vgg16BN\n",
    "    vgg16_bn = Vgg16BN()\n",
    "    c_layers, fc_layers = split_at(vgg16_bn.model, Convolution2D)\n",
    "    copy_weights(fc_layers, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_fc_weights_from_vgg16bn(bn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in bn_model.layers:\n",
    "    if type(l) is Dense:\n",
    "        l.set_weights(proc_wgts(l, .5, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path+'batchnorm_original_vgg_model.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_layers = bn_model.layers\n",
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: \n",
    "    layer.trainable = False\n",
    "for layer in bn_layers: \n",
    "    final_model.add(layer)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: use existing bn_vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "vgg16_bn = Vgg16BN()\n",
    "model = vgg16_bn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Option 2: Manual fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = Adam()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1606 images belonging to 2 classes.\n",
      "Found 1167 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "        height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
    "        channel_shift_range=10., horizontal_flip=True)\n",
    "batches = get_batches(path+'train', train_gen, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.N, nb_epoch=nb_epoch,\n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1606/1606 [==============================] - 112s - loss: 1.0713 - acc: 0.7628 - val_loss: 0.7521 - val_acc: 0.8123\n",
      "Epoch 2/4\n",
      "1606/1606 [==============================] - 91s - loss: 0.7886 - acc: 0.8275 - val_loss: 0.6311 - val_acc: 0.8115\n",
      "Epoch 3/4\n",
      "1606/1606 [==============================] - 94s - loss: 0.7222 - acc: 0.8418 - val_loss: 0.6127 - val_acc: 0.8046\n",
      "Epoch 4/4\n",
      "1606/1606 [==============================] - 92s - loss: 0.7444 - acc: 0.8319 - val_loss: 0.3819 - val_acc: 0.8817\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'bn_finetune_e4_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path+'bn_finetune_e4_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1606/1606 [==============================] - 117s - loss: 0.6672 - acc: 0.8456 - val_loss: 0.3188 - val_acc: 0.9135\n",
      "Epoch 2/2\n",
      "1606/1606 [==============================] - 94s - loss: 0.7100 - acc: 0.8369 - val_loss: 0.3218 - val_acc: 0.8886\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'bn_finetune_e14_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning previous layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "# Get the index of the first dense layer...\n",
    "first_dense_idx = [index for index,layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "# ...and set this and all subsequent layers to trainable\n",
    "for layer in layers[first_dense_idx:]: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1606/1606 [==============================] - 104s - loss: 0.6555 - acc: 0.8537 - val_loss: 0.4676 - val_acc: 0.8946\n",
      "Epoch 2/4\n",
      "1606/1606 [==============================] - 98s - loss: 0.6732 - acc: 0.8462 - val_loss: 0.4151 - val_acc: 0.8963\n",
      "Epoch 3/4\n",
      "1606/1606 [==============================] - 89s - loss: 0.6263 - acc: 0.8549 - val_loss: 0.3903 - val_acc: 0.9109\n",
      "Epoch 4/4\n",
      "1606/1606 [==============================] - 101s - loss: 0.6615 - acc: 0.8456 - val_loss: 0.4324 - val_acc: 0.9015\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.01\n",
    "fit_model(model, batches, val_batches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'bn_finetune_dense_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in layers[12:]: layer.trainable=True\n",
    "# K.set_value(opt.lr, 0.001)\n",
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1606/1606 [==============================] - 109s - loss: 0.5472 - acc: 0.8711 - val_loss: 0.3278 - val_acc: 0.9143\n",
      "Epoch 2/4\n",
      "1606/1606 [==============================] - 87s - loss: 0.5676 - acc: 0.8580 - val_loss: 0.3124 - val_acc: 0.9160\n",
      "Epoch 3/4\n",
      "1606/1606 [==============================] - 101s - loss: 0.6577 - acc: 0.8431 - val_loss: 0.4744 - val_acc: 0.8903\n",
      "Epoch 4/4\n",
      "1542/1606 [===========================>..] - ETA: 1s - loss: 0.6119 - acc: 0.8645"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'manual_finetune_12th_layer_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = vgg.model.predict_classes(val_data, batch_size=batch_size)\n",
    "# probs = vgg.model.predict_proba(val_data, batch_size=batch_size)[:,0]\n",
    "# probs[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "cm = confusion_matrix(val_classes, preds)\n",
    "print(cm)\n",
    "print(sklearn.metrics.f1_score(val_classes, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, {'noninvasive':0, 'invasive':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict results in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testFolder = path+'test/'\n",
    "\n",
    "# another test directory embeded in test folder\n",
    "embeddedFolder = testFolder+'test/'\n",
    "_, _, files = os.walk(embeddedFolder).next()\n",
    "num_test_images = len(files)\n",
    "test_batch_size = 100\n",
    "\n",
    "print(num_test_images)\n",
    "# num_test_images = 8\n",
    "# test_batch_size = 1\n",
    "\n",
    "batches = vgg.get_batches(testFolder, batch_size=test_batch_size, shuffle=False, class_mode=None)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "filenames = batches.filenames\n",
    "filename = filenames[0]\n",
    "print(filename)\n",
    "\n",
    "p = re.compile('.*/([0-9]+).jpg')\n",
    "m = p.match(filename)\n",
    "m.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our predictions..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing batch results\n",
    "test_batch_size = 10\n",
    "# test_sample_folder = path+'sample/test/'\n",
    "\n",
    "batches = vgg.get_batches(testFolder, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "# batches = vgg.get_batches(test_sample_folder, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "imgs = next(batches)\n",
    "labels, a, b = vgg.predict(imgs, True)\n",
    "\n",
    "# This shows the 'ground truth'\n",
    "plots(imgs, titles=labels)\n",
    "\n",
    "p = vgg.model.predict_on_batch(imgs)\n",
    "print(p)\n",
    "print(labels)\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert file names to label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "filenames = batches.filenames\n",
    "\n",
    "p = re.compile('.*/([0-9]+).jpg')\n",
    "def find_file_id(filename):\n",
    "    m = p.match(filename)\n",
    "    if m is not None:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        print('Could not regex filename: ', filename)\n",
    "        return -1\n",
    "file_ids = map(find_file_id, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option A: Predict values using vgg test function (Not recommended. No progress)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing batch results\n",
    "batches, predictions = vgg.test(testFolder, batch_size=1)\n",
    "# print('A: ', batches)\n",
    "p_results = predictions[:, 1]\n",
    "\n",
    "print('Predictions: ', p_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option B: Predict values with batches and progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "predict_file = model_path + 'predict.bc'\n",
    "\n",
    "def predict_test():\n",
    "    batches = vgg.get_batches(testFolder, batch_size=test_batch_size, shuffle=False, class_mode=None)\n",
    "\n",
    "    p_results = np.zeros(num_test_images)\n",
    "    current_index = 0\n",
    "    # Iterative loop\n",
    "    for batch in tqdm(batches, total=math.ceil(num_test_images/test_batch_size)):\n",
    "        if batch is None:\n",
    "            break\n",
    "        p = vgg.model.predict_on_batch(batch)\n",
    "        p_true = p[:, 1]\n",
    "        p_size = p.shape[0]\n",
    "#         print('Predictions: {}\\n Size: {}'.format(p_true, p_size))\n",
    "        new_index = current_index + p_size\n",
    "#         print('Current index: {} New index: {} PResults: {}'.format(current_index, new_index, p_results))\n",
    "        p_results[current_index:new_index] = p_true\n",
    "        current_index = new_index\n",
    "        if current_index >= num_test_images:\n",
    "            break\n",
    "    print(p_results)\n",
    "    utils.save_array(predict_file, p_results)\n",
    "    return p_results\n",
    "\n",
    "if os.path.exists(predict_file):\n",
    "    p_results = utils.load_array(predict_file)\n",
    "    print('Loaded predictions from cache')\n",
    "else:\n",
    "    p_results = predict_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the arrays match\n",
    "print(p_results.shape)\n",
    "print(len(file_ids))\n",
    "print(p_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rounded_results = np.rint(p_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clip results for better log loss\n",
    "clipped_results = np.clip(p_results, 0.05, 0.95)\n",
    "\n",
    "clipped_file = model_path + 'clip.bc'\n",
    "utils.save_array(clipped_file, clipped_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load saved clip file\n",
    "clipped_file = models_folder + 'clip.bc'\n",
    "clipped_results = load_array(clipped_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine ids with labels and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "agg = pd.DataFrame({'name': file_ids, 'invasive': clipped_results})\n",
    "agg = agg[agg.columns[::-1]]\n",
    "# agg = pd.DataFrame([file_ids, clipped_results], columns=['name', 'invasive'])\n",
    "agg = agg.sort_values(['name'])\n",
    "print(agg)\n",
    "agg.to_csv(path + 'clipped.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(path+'clipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!kg config -g -c 'invasive-species-monitoring'\n",
    "!kg submit {path+'clipped.csv'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
